# ğŸ”¥ GPU è´Ÿè½½æµ‹è¯•å·¥å…·ä½¿ç”¨æŒ‡å—

## ğŸ“ å·¥å…·ä»‹ç»

`test_gpu_load.py` æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæµ‹è¯•GPUä»»åŠ¡ç›‘æ§ç³»ç»Ÿçš„å·¥å…·ï¼Œå¯ä»¥ï¼š
- âœ… å æ»¡æŒ‡å®šGPUçš„æ˜¾å­˜
- âœ… ä¿æŒGPUé«˜åˆ©ç”¨ç‡è¿è¡Œ
- âœ… æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªGPUåŒæ—¶æµ‹è¯•
- âœ… å¯è‡ªå®šä¹‰è¿è¡Œæ—¶é—´å’Œæ˜¾å­˜å ç”¨æ¯”ä¾‹
- âœ… æ”¯æŒéšæ—¶åœæ­¢ï¼ˆCtrl+Cï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®æ¡ä»¶

éœ€è¦å®‰è£… PyTorchï¼š

```bash
# CPUç‰ˆæœ¬ï¼ˆç”¨äºæµ‹è¯•ï¼‰
pip install torch

# GPUç‰ˆæœ¬ï¼ˆæ¨èï¼Œæ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
# CUDA 11.8
pip install torch --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### åŸºæœ¬ç”¨æ³•

```bash
# 1. å æ»¡ GPU 0ï¼ˆé»˜è®¤ä½¿ç”¨90%æ˜¾å­˜ï¼‰
python test_gpu_load.py -g 0

# 2. å æ»¡ GPU 1ï¼Œè¿è¡Œ300ç§’åè‡ªåŠ¨åœæ­¢
python test_gpu_load.py -g 1 -d 300

# 3. å æ»¡ GPU 0ï¼Œä½¿ç”¨80%æ˜¾å­˜
python test_gpu_load.py -g 0 -m 0.8

# 4. åŒæ—¶å æ»¡å¤šä¸ªGPUï¼ˆGPU 0, 1, 2ï¼‰
python test_gpu_load.py -g 0,1,2
```

## ğŸ“– å‚æ•°è¯´æ˜

| å‚æ•° | ç®€å†™ | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|------|--------|------|
| `--gpu` | `-g` | GPU IDï¼ˆå¿…éœ€ï¼‰ï¼Œå¤šä¸ªGPUç”¨é€—å·åˆ†éš” | - | `-g 0` æˆ– `-g 0,1,2` |
| `--memory` | `-m` | æ˜¾å­˜å ç”¨æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰ | 0.9 (90%) | `-m 0.8` (80%) |
| `--duration` | `-d` | æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œä¸æŒ‡å®šåˆ™ä¸€ç›´è¿è¡Œ | None | `-d 300` (5åˆ†é’Ÿ) |
| `--size` | `-s` | çŸ©é˜µå¤§å°ï¼ˆå½±å“æ˜¾å­˜åˆ†é…ç²’åº¦ï¼‰ | 10000 | `-s 5000` (å°æ˜¾å­˜GPU) |

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæµ‹è¯•è¿›ç¨‹ç›‘æ§åŠŸèƒ½

```bash
# å¯åŠ¨GPUä»»åŠ¡
python test_gpu_load.py -g 0 -d 600

# ç„¶ååœ¨Webç•Œé¢ï¼š
# 1. è¿›å…¥"ä»»åŠ¡ç›‘æ§"é¡µé¢
# 2. ç‚¹å‡»"æ–°å»ºä»»åŠ¡ç›‘æ§"
# 3. é€‰æ‹©"è¿›ç¨‹ç›‘æ§"
# 4. é€‰æ‹©å¯¹åº”çš„æœåŠ¡å™¨å’Œè¿›ç¨‹
# 5. å¡«å†™é‚®ç®±ï¼Œåˆ›å»ºç›‘æ§

# ç­‰å¾…600ç§’åï¼Œä»»åŠ¡ç»“æŸï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å‘é€é‚®ä»¶é€šçŸ¥
```

### åœºæ™¯2ï¼šæµ‹è¯•GPUç©ºé—²ç›‘å¬

```bash
# å…ˆç¡®ä¿GPUä¸Šæœ‰ä»»åŠ¡è¿è¡Œ
python test_gpu_load.py -g 1 -d 180

# åœ¨Webç•Œé¢åˆ›å»º"ç©ºå¡ç›‘å¬"ï¼š
# 1. é€‰æ‹©"ç©ºå¡ç›‘å¬"ç±»å‹
# 2. é€‰æ‹©GPU 1
# 3. å¡«å†™é‚®ç®±

# 180ç§’åï¼ŒGPUå˜ç©ºé—²ï¼Œç³»ç»Ÿä¼šå‘é€é€šçŸ¥é‚®ä»¶
```

### åœºæ™¯3ï¼šé•¿æ—¶é—´è´Ÿè½½æµ‹è¯•

```bash
# å æ»¡GPU 0ï¼ŒæŒç»­1å°æ—¶
python test_gpu_load.py -g 0 -d 3600
```

### åœºæ™¯4ï¼šå¤šGPUå‹åŠ›æµ‹è¯•

```bash
# åŒæ—¶å æ»¡æ‰€æœ‰GPUï¼Œæ¯ä¸ªä½¿ç”¨85%æ˜¾å­˜
python test_gpu_load.py -g 0,1,2,3 -m 0.85
```

### åœºæ™¯5ï¼šå°æ˜¾å­˜GPUæµ‹è¯•

```bash
# å¯¹äºæ˜¾å­˜è¾ƒå°çš„GPUï¼ˆå¦‚2-4GBï¼‰ï¼Œä½¿ç”¨è¾ƒå°çš„çŸ©é˜µ
python test_gpu_load.py -g 0 -s 5000 -m 0.7
```

## ğŸ’¡ è¿è¡Œç¤ºä¾‹

### ç¤ºä¾‹è¾“å‡º

```bash
$ python test_gpu_load.py -g 0 -m 0.8 -d 300

æ£€æµ‹åˆ° 4 ä¸ªGPU:
  GPU 0: NVIDIA GeForce RTX 3090 (24.00 GB)
  GPU 1: NVIDIA GeForce RTX 3090 (24.00 GB)
  GPU 2: NVIDIA GeForce RTX 3080 (10.00 GB)
  GPU 3: NVIDIA GeForce RTX 3080 (10.00 GB)

[GPU 0] å¼€å§‹å ç”¨æ˜¾å¡: NVIDIA GeForce RTX 3090
[GPU 0] æ€»æ˜¾å­˜: 24.00 GB
[GPU 0] ç›®æ ‡å ç”¨: 19.20 GB (80.0%)
[GPU 0] çŸ©é˜µå¤§å°: 10000x10000
[GPU 0] æŒç»­æ—¶é—´: 300 ç§’

[GPU 0] æ­£åœ¨åˆ†é…æ˜¾å­˜...
[GPU 0] å·²åˆ†é…: 19.20/19.20 GB (100.0%)
[GPU 0] æ˜¾å­˜åˆ†é…å®Œæˆï¼
[GPU 0] å®é™…å ç”¨: 19.20 GB
[GPU 0] å¼€å§‹å¯†é›†è®¡ç®—...
[GPU 0] è¿è¡Œä¸­... å·²è¿è¡Œ 10.5ç§’ | æ˜¾å­˜: 19.20GB (ä¿ç•™: 19.22GB) | è¿­ä»£: 50
[GPU 0] è¿è¡Œä¸­... å·²è¿è¡Œ 20.8ç§’ | æ˜¾å­˜: 19.20GB (ä¿ç•™: 19.22GB) | è¿­ä»£: 100
...
[GPU 0] å·²è¾¾åˆ°æŒ‡å®šæ—¶é—´ 300 ç§’
[GPU 0] æ­£åœ¨æ¸…ç†æ˜¾å­˜...
[GPU 0] æ¸…ç†å®Œæˆ
```

## ğŸ›‘ åœæ­¢è¿è¡Œ

å¯ä»¥éšæ—¶æŒ‰ `Ctrl+C` åœæ­¢ï¼š

```
[GPU 0] è¿è¡Œä¸­... å·²è¿è¡Œ 45.3ç§’ | æ˜¾å­˜: 19.20GB | è¿­ä»£: 215
^C
[GPU 0] æ¥æ”¶åˆ°åœæ­¢ä¿¡å· (Ctrl+C)
[GPU 0] æ­£åœ¨æ¸…ç†æ˜¾å­˜...
[GPU 0] æ¸…ç†å®Œæˆ
```

## ğŸ“Š ç›‘æ§çŠ¶æ€

è¿è¡Œè„šæœ¬çš„åŒæ—¶ï¼Œå¯ä»¥ä½¿ç”¨ `nvidia-smi` æŸ¥çœ‹GPUçŠ¶æ€ï¼š

```bash
# å¦å¼€ä¸€ä¸ªç»ˆç«¯
watch -n 1 nvidia-smi

# æˆ–è€…
nvidia-smi dmon -s u
```

ä½ ä¼šçœ‹åˆ°ï¼š
- **æ˜¾å­˜å ç”¨**æ¥è¿‘æŒ‡å®šæ¯”ä¾‹ï¼ˆå¦‚90%ï¼‰
- **GPUåˆ©ç”¨ç‡**æŒç»­æ¥è¿‘100%
- **è¿›ç¨‹åˆ—è¡¨**æ˜¾ç¤ºPythonè¿›ç¨‹

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ˜¾å­˜å ç”¨
- é»˜è®¤å ç”¨90%æ˜¾å­˜ï¼Œç•™10%ç»™ç³»ç»Ÿ
- å¦‚æœéœ€è¦æ›´é«˜å ç”¨ç‡ï¼Œå¯è®¾ç½® `-m 0.95`ï¼ˆ95%ï¼‰
- ä¸å»ºè®®è®¾ç½®ä¸º1.0ï¼ˆ100%ï¼‰ï¼Œå¯èƒ½å¯¼è‡´ç³»ç»Ÿä¸ç¨³å®š

### 2. çŸ©é˜µå¤§å°è°ƒæ•´
- **å¤§æ˜¾å­˜GPUï¼ˆ16GB+ï¼‰**ï¼šä½¿ç”¨é»˜è®¤ `-s 10000` æˆ–æ›´å¤§ `-s 15000`
- **ä¸­ç­‰æ˜¾å­˜GPUï¼ˆ8-12GBï¼‰**ï¼šä½¿ç”¨é»˜è®¤ `-s 10000`
- **å°æ˜¾å­˜GPUï¼ˆ4-6GBï¼‰**ï¼šä½¿ç”¨è¾ƒå° `-s 5000` æˆ– `-s 7000`

çŸ©é˜µè¶Šå¤§ï¼Œæ¯æ¬¡åˆ†é…çš„æ˜¾å­˜å—è¶Šå¤§ï¼Œåˆ†é…æ¬¡æ•°è¶Šå°‘ã€‚

### 3. å¤šGPUè¿è¡Œ
- å¤šGPUæ¨¡å¼ä½¿ç”¨å¤šè¿›ç¨‹ï¼Œæ¯ä¸ªGPUç‹¬ç«‹è¿è¡Œ
- å¯ä»¥åŒæ—¶æŒ‰ `Ctrl+C` åœæ­¢æ‰€æœ‰GPU

### 4. æƒé™é—®é¢˜
å¦‚æœæç¤ºæƒé™ä¸è¶³ï¼š
```bash
chmod +x test_gpu_load.py
```

### 5. æ˜¾å­˜ä¸è¶³
å¦‚æœé‡åˆ° "CUDA out of memory" é”™è¯¯ï¼š
- é™ä½æ˜¾å­˜å ç”¨æ¯”ä¾‹ï¼š`-m 0.7` æˆ– `-m 0.6`
- å‡å°çŸ©é˜µå¤§å°ï¼š`-s 5000`

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1ï¼šæ‰¾ä¸åˆ°CUDA GPU

```
é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°CUDA GPU
```

**è§£å†³æ–¹æ¡ˆï¼š**
- ç¡®è®¤GPUé©±åŠ¨å·²å®‰è£…ï¼š`nvidia-smi`
- ç¡®è®¤PyTorch GPUç‰ˆæœ¬å·²å®‰è£…ï¼š`python -c "import torch; print(torch.cuda.is_available())"`

### é—®é¢˜2ï¼šæ˜¾å­˜åˆ†é…å¤±è´¥

```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# é™ä½æ˜¾å­˜å ç”¨
python test_gpu_load.py -g 0 -m 0.6

# æˆ–å‡å°çŸ©é˜µå¤§å°
python test_gpu_load.py -g 0 -s 5000
```

### é—®é¢˜3ï¼šGPU ID ä¸å­˜åœ¨

```
é”™è¯¯ï¼šGPU 2 ä¸å­˜åœ¨ï¼ˆå¯ç”¨èŒƒå›´: 0-1ï¼‰
```

**è§£å†³æ–¹æ¡ˆï¼š**
- è¿è¡Œ `nvidia-smi` æŸ¥çœ‹å¯ç”¨çš„GPU ID
- ä½¿ç”¨æ­£ç¡®çš„GPU ID

## ğŸ“ˆ æ€§èƒ½è¯´æ˜

- **CPUä½¿ç”¨**ï¼šå¾ˆä½ï¼ˆ5-10%ï¼‰ï¼Œä¸»è¦è´Ÿè½½åœ¨GPU
- **æ˜¾å­˜å ç”¨**ï¼šæ ¹æ® `-m` å‚æ•°æ§åˆ¶
- **GPUåˆ©ç”¨ç‡**ï¼šæŒç»­80-100%
- **åŠŸè€—**ï¼šæ¥è¿‘GPU TDPä¸Šé™

## ğŸ“ è¿›é˜¶ç”¨æ³•

### 1. åå°è¿è¡Œ

```bash
# ä½¿ç”¨ nohup
nohup python test_gpu_load.py -g 0 -d 3600 > gpu0.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f gpu0.log
```

### 2. å®šæ—¶ä»»åŠ¡

```bash
# æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œ1å°æ—¶GPUæµ‹è¯•
crontab -e

# æ·»åŠ ï¼š
0 2 * * * cd /path/to/gpu-server-manager && python test_gpu_load.py -g 0 -d 3600
```

### 3. é…åˆç›‘æ§ä½¿ç”¨

```bash
# å¯åŠ¨GPUæµ‹è¯•
python test_gpu_load.py -g 0 -d 600 &

# åŒæ—¶ç›‘æ§
watch -n 1 'nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv'
```

## ğŸ“š ç›¸å…³å‘½ä»¤

```bash
# æŸ¥çœ‹GPUä¿¡æ¯
nvidia-smi

# æŒç»­ç›‘æ§GPU
watch -n 1 nvidia-smi

# æŸ¥çœ‹æŒ‡å®šGPU
nvidia-smi -i 0

# æŸ¥çœ‹è¿›ç¨‹
nvidia-smi pmon

# æ€æ­»GPUè¿›ç¨‹
kill -9 <PID>
```

## ğŸ†˜ è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹å®Œæ•´å¸®åŠ©
python test_gpu_load.py -h

# æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯
python test_gpu_load.py --help
```

---

**æç¤ºï¼š** è¿™ä¸ªå·¥å…·ä¸“é—¨ç”¨äºæµ‹è¯•ä»»åŠ¡ç›‘æ§ç³»ç»Ÿï¼Œä¸å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é•¿æ—¶é—´è¿è¡Œã€‚
